{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from clickhouse_driver import Client\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lunch_duration = '23-29Nov2024'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# تنظیمات اتصال به ClickHouse\n",
    "client = Client(\n",
    "    host=\"172.21.16.1\", \n",
    "    port=\"9000\", \n",
    "    user='alireza_mohammadi', \n",
    "    password='4qNSwyNNlZ@Os0r8%#R7'\n",
    ")\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    code AS promoter_code,\n",
    "    name_clear,\n",
    "    cellphone_clear,\n",
    "    city_id,\n",
    "    m.state_en_3w as city,\n",
    "    MAX(updated_at) AS updated_at\n",
    "FROM \n",
    "    snapp_promoters.stream_users p\n",
    "JOIN minio_db.operations_district_info m ON m.state_id = p.city_id\n",
    "GROUP BY\n",
    "    promoter_code, name_clear, cellphone_clear, city_id, m.state_en_3w\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clickhouse_data = client.execute(query)\n",
    "clickhouse_df = pd.DataFrame(clickhouse_data, columns=['promoter_code', 'name_clear', 'cellphone_clear', 'city_id', 'city', 'updated_at'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# خواندن فایل اکسل\n",
    "df = pd.read_excel('E:/data/Data_Launch.xlsx', sheet_name='Final')\n",
    "df_enriched = pd.read_excel('E:/data/Data_Launch.xlsx', sheet_name='Enriched')\n",
    "quality_list = pd.read_excel('E:/data/Data_Launch.xlsx', sheet_name='quality_list')\n",
    "df['promoter_code'] = df['promoter_code'].astype(str).str.strip()\n",
    "clickhouse_df['promoter_code'] = clickhouse_df['promoter_code'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df[df['Eligibility'] != 'MayBeNextWeek']\n",
    "df=df[df['Role'] == 'ON_SPOT_PROMOTER']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snapp\\AppData\\Local\\Temp\\ipykernel_22896\\3608582873.py:1: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df.promoter_code = pd.to_numeric(df.promoter_code , errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "df.promoter_code = pd.to_numeric(df.promoter_code , errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# مرحله 1: فیلتر کردن پروموترهای Eligibility شده\n",
    "filtered_df = df[df['Eligibility'] == 'Eligible']\n",
    "\n",
    "# مرحله 2: ترکیب داده‌ها با اطلاعات شیت Enriched\n",
    "enriched_filtered_df = filtered_df.merge(\n",
    "    df_enriched[['promoter_code', 'quality_trained_place']],  # انتخاب ستون‌های مرتبط از شیت Enriched\n",
    "    on='promoter_code',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# مرحله 3: انتخاب ردیف‌های با بهترین کیفیت (فرض می‌کنیم quality_police امتیازی است و باید بیشینه باشد)\n",
    "enriched_filtered_df = enriched_filtered_df.sort_values(by='quality_trained_place', ascending=False).drop_duplicates(subset=['promoter_code'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# پرومتر کدهای خاص که باید منتقل شوند\n",
    "blacklist_promoter_codes = [\n",
    "    24511, 76813, 28312, 35798, 25466, 24397, 18196, 95653, 71160, 87238,\n",
    "    12719, 73838, 73749, 32655, 79781, 25519, 91761, 90583, 80222, 73473,\n",
    "    50772, 92552, 76175, 46578, 38237, 81568, 52661, 58435, 84085, 51762,\n",
    "    89915, 65323, 54952, 92874, 81061, 91610, 82608, 10014, 78810, 87774,\n",
    "    80356, 65853, 40313, 31850, 42369, 61433, 50118, 71667, 92190, 77212,\n",
    "    26822, 40423, 34828, 69728, 42939, 20561, 93202, 33154, 14550, 46388,\n",
    "    42011, 96041, 31642, 90159, 92431, 93565, 67082, 27509, 97752, 36436,\n",
    "    89334, 46586, 55424, 51911, 95519, 90601, 24752, 18601, 11188, 49292,\n",
    "    66086, 85606, 51623, 59435, 10768, 25713, 75829, 59149, 96563, 36158,\n",
    "    95684, 46657, 78477, 34001, 77236, 35163, 91819, 11722, 85601, 84036,\n",
    "    60661, 93929, 71269, 96533, 65024, 49796, 54447, 87329, 15080, 75592,\n",
    "    69644, 30750, 48503, 50954, 60099, 80389, 92740, 73896, 19386, 57196,\n",
    "    34851, 61519, 60446, 92939, 63152, 16951, 78258, 64295, 11646, 93644\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snapp\\AppData\\Local\\Temp\\ipykernel_22896\\3600487540.py:1: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  clickhouse_df.promoter_code = pd.to_numeric(clickhouse_df.promoter_code , errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "clickhouse_df.promoter_code = pd.to_numeric(clickhouse_df.promoter_code , errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# حذف رکوردهای تکراری در clickhouse_df بر اساس 'promoter_code'\n",
    "clickhouse_df = clickhouse_df.drop_duplicates(subset='promoter_code')\n",
    "\n",
    "# # حذف پیش‌شماره +98 از شماره‌های موبایل\n",
    "clickhouse_df['cellphone_clear'] = clickhouse_df['cellphone_clear'].str.replace(r'^\\+98', '', regex=True)\n",
    "\n",
    "\n",
    "# ادغام دیتافریم‌ها\n",
    "enriched_filtered_df2 = pd.merge(enriched_filtered_df, clickhouse_df[['promoter_code', 'name_clear', 'cellphone_clear','city']].drop_duplicates(subset='promoter_code'), on='promoter_code', how='left')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# انتخاب ستون‌های نهایی\n",
    "columns_to_save = ['promoter_code', 'City', 'name_clear', 'cellphone_clear' , 'quality_trained_place']  # اضافه کردن نام به ستون‌ها\n",
    "merged_df = enriched_filtered_df2[columns_to_save]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snapp\\AppData\\Local\\Temp\\ipykernel_22896\\1210167359.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  blacklisted_df['Week'] = f'{lunch_duration}'\n",
      "C:\\Users\\Snapp\\AppData\\Local\\Temp\\ipykernel_22896\\1210167359.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  payment_df['Rial'] = 5600000\n",
      "C:\\Users\\Snapp\\AppData\\Local\\Temp\\ipykernel_22896\\1210167359.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  payment_df['Description'] = f'Lunch incentive {lunch_duration}'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "blacklisted_df = merged_df[merged_df['promoter_code'].isin(blacklist_promoter_codes)]\n",
    "blacklisted_df['Week'] = f'{lunch_duration}'\n",
    "\n",
    "\n",
    "not_black_listed = merged_df[~merged_df['promoter_code'].isin(blacklist_promoter_codes)]\n",
    "#فیلتر کردن رکوردهایی که شامل کوالیتی‌های خاص هستند\n",
    "payment_df = not_black_listed[not_black_listed['quality_trained_place'].isin(quality_list['quality_trained_place'].tolist())]\n",
    "payment_df['Rial'] = 5600000\n",
    "payment_df['Description'] = f'Lunch incentive {lunch_duration}'\n",
    "\n",
    "\n",
    "# حذف کوالیتی‌های خاص از دیتافریم اصلی\n",
    "winner_df = not_black_listed[~not_black_listed['quality_trained_place'].isin(quality_list['quality_trained_place'].tolist())]\n",
    "# حذف سطرهایی که کلمه 'پروموتر' در ستون 'name_clear' یا کلمات خاص در ستون 'City' وجود دارد\n",
    "winner_df = winner_df[~winner_df['name_clear'].str.contains('پروموتر', case=False, na=False)]\n",
    "winner_df = winner_df[~winner_df['City'].str.contains('QES', case=False, na=False)]\n",
    "winner_df = winner_df[~winner_df['City'].str.contains('KIS', case=False, na=False)]\n",
    "\n",
    "# حذف سطرهایی که مقدار promoter_code آن‌ها -1 است\n",
    "winner_df = winner_df[winner_df['promoter_code'] != '-1']\n",
    "columns_main_data = ['promoter_code', 'City']\n",
    "columns_winner_data = ['cellphone_clear', 'City' ,'promoter_code']\n",
    "columns_payment_data = ['cellphone_clear', 'City' ,'promoter_code' , 'Rial' , 'Description']\n",
    "columns_blacklist_data = ['Week' , 'cellphone_clear', 'City' ,'promoter_code']\n",
    "columns_Blacklisted_Promoters = ['promoter_code', 'City', 'quality_trained_place']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to E:/data/output_file.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# مسیر ذخیره‌سازی فایل Excel\n",
    "output_file = 'E:/data/output_file.xlsx'\n",
    "\n",
    "# ایجاد فایل Excel با شیت‌های مختلف\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    # ذخیره دیتافریم‌ها در شیت‌های مختلف\n",
    "    winner_df.to_excel(writer, index=False, sheet_name='Winners')\n",
    "    payment_df.to_excel(writer, index=False, sheet_name='Payments')\n",
    "    blacklisted_df.to_excel(writer, index=False, sheet_name='Blacklisted')\n",
    "\n",
    "print(f\"Data has been saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
